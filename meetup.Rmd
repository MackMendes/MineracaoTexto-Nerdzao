---
title: "R Notebook"
output: html_notebook
author: "Andrei Martins e Charles Mendes"
date: "04 de Novembro de 2017"
---

## Instalar e carregar pacotes

```{r, message=FALSE}
# Instala pacotes caso ainda não tenham sido instalados
if(!require(dplyr)) install.packages("dplyr")  # Manipulação de dados
if(!require(ggplot2)) install.packages("ggplot2") # Visualização de dados
if(!require(httpuv)) install.packages("httpuv")  # Suporte a HTTP e WebSocket
if(!require(lexiconPT)) install.packages("lexiconPT")  # Análise de Sentimento
if(!require(rtweet)) install.packages("rtweet")  # Cliente para Twitter Search API
if(!require(tidytext)) install.packages("tidytext") # Mineração de textos
if(!require(wordcloud)) install.packages("wordcloud") # Visualização de textos
if(!require(RDRPOSTagger)) install.packages("RDRPOSTagger")  # Mineração de Textos
```

## Criar app no Twitter

1) Acesse https://apps.twitter.com e crie um novo aplicativo.
2) A fim demostração, no campo `Website` colocarmos a URL do nosso perfil do Twitter.  
3) No campo `Callback URL` preencher com: http://127.0.0.1:1410
4) Aceite os termos e clique em "Create your Twitter application".
5) Vá em "Keys and Access Tokens" e anote os valores dos campos `Consumer Key`, `Consumer Secret`. Eles serão utilizados para autenticação na próxima seção.

* (Ob.: Pode ser que o Twitter peça para incluir o número do seu celular, antes de criar o seu aplicativo. Só seguir as instruções: https://support.twitter.com/articles/270426.)

```{r}
## Nome do seu aplicativo (o mesmo criado na etapa anterior)
nomeAplicativo <- "nerdzao" 

## Consumer Key (API Key)
chaveAPI <- "29lJMLodwnkMNO6guU435B5K1"

## Consumer Secret (API Secret)
chaveSecreta <- "6IIjtDyaFftDZc6E58l7mZojEmTJWnIQM2cdrA62ICFX6ZfRBm"

## Criar token para o app
twitter_token <- create_token(app = nomeAplicativo, 
                              consumer_key = chaveAPI, 
                              consumer_secret = chaveSecreta)
```

## Coleta de dados

Vamos coletar e preparar os dados dos *tweets* dos 4 grandes clubes paulistas (Corinthians, Palmeiras, Santos e São Paulo).
Para isso, vamos:

1) Definir a lista de clubes
2) Fazer a requisição à Search API do Twitter
3) Consolidar as requisições em uma única tabela
4) Selecionar colunas de interesse
5) Salvar dados para uso posterior

```{r, message=FALSE}
# 0) Carregar dados para evitar consulta ao Twitter
load("tweets_clubes.RData")

# 1) Definir a lista de clubes
clubes <- c("@Corinthians", "@Palmeiras", "@SantosFC", "@SaoPauloFC")

# 2) Fazer a requisição à Search API do Twitter
# Extrai 200 tweets sobre cada clube especificado, totalizando 800 tweets
# tweets <- lapply(clubes, search_tweets, n = 200, token = twitter_token)

# 3) Consolidar as requisições em uma única tabela
tw_sccp <- tweets[[1]] %>%
  mutate(clube = "Corinthians")
tw_sep  <- tweets[[2]] %>%
  mutate(clube = "Palmeiras")
tw_sfc  <- tweets[[3]] %>%
  mutate(clube = "Santos")
tw_spfc <- tweets[[4]] %>%
  mutate(clube = "São Paulo")

tweets_clubes <- rbind(tw_sccp, tw_sep, tw_sfc, tw_spfc)

# 4) Selecionar colunas de interesse
tweets_clubes <- tweets_clubes %>%
  select(clube, text, created_at)

# 5) Salvar dados para uso posterior
# save(tweets, tweets_clubes, file = "tweets_clubes.RData") # Salvar para uso posterior
```

## Nuvens de palavras (wordclouds)

Vamos contar a ocorrência de palavras para cada clube e depois plotar a nuvem de
palavras de cada clube.
```{r}
top_words <- tweets_clubes %>%
  unnest_tokens(term, text) %>%
  count(clube, term, sort = TRUE)

top_words
```

### Corinthians
```{r, warning=FALSE}
top_sccp <- top_words %>%
  filter(clube == "Corinthians")
  
wordcloud(top_sccp$term, top_sccp$n)
```

### Palmeiras
```{r, warning=FALSE}
top_sep <- top_words %>%
  filter(clube == "Palmeiras")
  
wordcloud(top_sep$term, top_sep$n, colors = brewer.pal(9, "Greens"))
```
### Santos
```{r, warning=FALSE}
top_sfc <- top_words %>%
  filter(clube == "Santos")
  
wordcloud(top_sfc$term, top_sfc$n)
```

### São Paulo
```{r, warning=FALSE}
top_spfc <- top_words %>%
  filter(clube == "São Paulo")
  
wordcloud(top_spfc$term, top_spfc$n, colors = brewer.pal(9, "Reds"))
```

## Análise de Sentimento

Cada palavra carrega consigo um sentimento que pode ser bom (1), neutro (0) ou ruim (-1). 
Vamos ver o sentimento transmitidos por algumas palavras.
```{r}
dicio <- oplexicon_v3.0 # Carrega dicionário de sentimentos

# Sentimento transmitido pela palavra "inteligente"
dicio %>%
  filter(term == "inteligente") %>%
  select(term, polarity)

# Sentimento transmitido pela palavra "academico"
dicio %>%
  filter(term == "academico") %>%
  select(term, polarity)

# Sentimento transmitido pela palavra "lento"
dicio %>%
  filter(term == "lento") %>%
  select(term, polarity)
```

### Corinthians

```{r, message=FALSE}

# Análise de sentimento dos tweets referentes ao Corinthians
sentimento_sccp <- tweets_clubes %>%
  filter(clube == "Corinthians") %>%  # Apenas tweets referentes ao Corinthians
  unnest_tokens(term, text) %>%       # Quebra os tweets em palavras
  inner_join(dicio) %>%               
  count(term, polarity, sort = TRUE) %>%
  ungroup()

sentimento_sccp
```

### Palmeiras

```{r, message=FALSE}

# Análise de sentimento dos tweets referentes ao Corinthians
sentimento_sep <- tweets_clubes %>%
  filter(clube == "Palmeiras") %>%  # Apenas tweets referentes ao Corinthians
  unnest_tokens(term, text) %>%     # Quebra os tweets em palavras
  inner_join(dicio) %>%               
  count(term, polarity, sort = TRUE) %>%
  ungroup()

sentimento_sep
```

### Santos

```{r, message=FALSE}

# Análise de sentimento dos tweets referentes ao Corinthians
sentimento_sfc <- tweets_clubes %>%
  filter(clube == "Santos") %>%  # Apenas tweets referentes ao Corinthians
  unnest_tokens(term, text) %>%     # Quebra os tweets em palavras
  inner_join(dicio) %>%               
  count(term, polarity, sort = TRUE) %>%
  ungroup()

sentimento_sfc
```


### São Paulo

```{r, message=FALSE}

# Análise de sentimento dos tweets referentes ao Corinthians
sentimento_spfc <- tweets_clubes %>%
  filter(clube == "São Paulo") %>%  # Apenas tweets referentes ao Corinthians
  unnest_tokens(term, text) %>%     # Quebra os tweets em palavras
  inner_join(dicio) %>%               
  count(term, polarity, sort = TRUE) %>%
  ungroup()

sentimento_spfc
```

### Sentimento Geral
```{r, message = FALSE}
tweets_clubes %>%
  unnest_tokens(term, text) %>%
  inner_join(dicio) %>%
  group_by(clube) %>%
  summarise(sum(polarity)) %>%
  ggplot(aes(clube, `sum(polarity)`)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Clube", y = "Sentimento")
```

## Calculando a frequência das palavras (tf)


Vamos calcular a frequência das palavras dentro dos Twitters dos clubes: 

```{r}

texto_clubes <- tweets_clubes %>%
  unnest_tokens(termo, text) %>%
  count(clube, termo, sort = TRUE) %>%
  ungroup()


total_texto_clubes <- texto_clubes %>% 
  group_by(clube) %>% 
  summarize(total = sum(n))


texto_clubes <- left_join(texto_clubes, total_texto_clubes)

texto_clubes

```


Agora, realizarmos o calculo da Frequencia dos Termos (TF) por time:

```{r}

tf_texto_clubes_by_rank <- texto_clubes %>% 
  group_by(clube) %>% 
  mutate(rank = row_number(), 
         `TF` = n/total)

tf_texto_clubes_by_rank

```

E por fim, plotando os termos:

```{r}

plot_austen <- tf_texto_clubes_by_rank %>%
  ungroup(tf_texto_clubes_by_rank) %>%
  arrange(desc(TF)) %>%
  mutate(termo = factor(termo, levels = rev(unique(termo))))

plot_austen %>% 
  top_n(20) %>%
  ggplot(aes(termo, TF, fill = clube)) +
  geom_col() +
  labs(x = NULL, y = "Frequencia dos Termos (TF)") +
  coord_flip()

```


## Calculando a idf

```{r}

texto_clubes_tf_idf <- texto_clubes %>%
  bind_tf_idf(termo, clube, n)
texto_clubes_tf_idf

```





## Calculando o tf-idf


```{r}

texto_clubes_tf_idf <- texto_clubes %>%
  bind_tf_idf(termo, clube, n)
texto_clubes_tf_idf

```




```{r}

texto_clubes_tf_idf %>%
  select(-total) %>%
  arrange(desc(tf_idf))

```


```{r}

plot_clubes_tf_idf <- texto_clubes_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(termo = factor(termo, levels = rev(unique(termo))))

plot_clubes_tf_idf %>% 
  top_n(20) %>%
  ggplot(aes(termo, tf_idf, fill = clube)) +
  geom_col() +
  labs(x = NULL, y = "tf-idf") +
  coord_flip()

```



Agora, para cada clube: 


```{r}

plot_clubes_tf_idf %>% 
  group_by(clube) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(termo, tf_idf, fill = clube)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~clube, ncol = 2, scales = "free") +
  coord_flip()

```


## Bigrama

Abaixo, vamos calcular o Bigrama: 

```{r}

bigramas_tweets_clubes <- tweets_clubes %>%
  unnest_tokens(bigrama, text, token = "ngrams", n = 2)

bigramas_tweets_clubes

```

Recalculando o TF-IDF com o Bigrama: 

```{r}

bigramas_tweets_texto_clubes <- bigramas_tweets_clubes %>%
  count(clube, bigrama, sort = TRUE) %>%
  ungroup()


total_bigramas_tweets_texto_clubes <- bigramas_tweets_texto_clubes %>% 
  group_by(clube) %>% 
  summarize(total = sum(n))


bigramas_tweets_texto_clubes <- left_join(bigramas_tweets_texto_clubes, total_bigramas_tweets_texto_clubes)

bigramas_tweets_texto_clubes_tf_idf <- bigramas_tweets_texto_clubes %>%
  bind_tf_idf(bigrama, clube, n)


bigramas_tweets_texto_clubes_tf_idf %>%
  select(-total) %>%
  arrange(desc(tf_idf))

```

Vamos vê os plotes: 

```{r}

plot_clubes_tf_idf_bigrama <- bigramas_tweets_texto_clubes_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigrama = factor(bigrama, levels = rev(unique(bigrama))))

plot_clubes_tf_idf_bigrama %>% 
  top_n(20) %>%
  ggplot(aes(bigrama, tf_idf, fill = clube)) +
  geom_col() +
  labs(x = NULL, y = "TF-IDF dos Bigramas") +
  coord_flip()

```


Por cada clube: 

```{r}

plot_clubes_tf_idf_bigrama %>% 
  group_by(clube) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(bigrama, tf_idf, fill = clube)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "TF-IDF dos Bigramas por Clube") +
  facet_wrap(~clube, ncol = 2, scales = "free") +
  coord_flip()

```


## Referências

- [Cliente R para API do Twitter](https://github.com/mkearney/rtweet)
- [Text Mining With R](http://tidytextmining.com/)